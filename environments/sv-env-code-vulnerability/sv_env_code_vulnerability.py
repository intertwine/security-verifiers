"""Security Verifiers environment: code vulnerability repair with patch-and-test."""

from __future__ import annotations

import ast
import json
import textwrap
from dataclasses import dataclass
from difflib import SequenceMatcher, unified_diff
from pathlib import Path
from types import MappingProxyType
import sys
from typing import Any, Dict, Iterable, List, Optional, Set

from typing_extensions import TypedDict
from unidiff import PatchSet
from unidiff.errors import UnidiffParseError

import verifiers as vf
from datasets import Dataset

# Allow importing shared utilities when running from the repo root.
sys.path.append(str(Path(__file__).resolve().parents[2]))

from sv_shared import RolloutLogger, get_response_text  # type: ignore  # pylint: disable=wrong-import-position


_BASE_SAFE_BUILTINS: Dict[str, Any] = {
    "abs": abs,
    "all": all,
    "any": any,
    "bool": bool,
    "dict": dict,
    "enumerate": enumerate,
    "Exception": Exception,
    "float": float,
    "int": int,
    "isinstance": isinstance,
    "len": len,
    "list": list,
    "map": map,
    "max": max,
    "min": min,
    "object": object,
    "pow": pow,
    "print": print,
    "range": range,
    "round": round,
    "set": set,
    "sorted": sorted,
    "str": str,
    "sum": sum,
    "tuple": tuple,
    "zip": zip,
    "ValueError": ValueError,
    "TypeError": TypeError,
    "AssertionError": AssertionError,
}

_ALLOWED_IMPORT_MODULES: Set[str] = {
    "yaml",
    "json",
    "re",
    "math",
    "datetime",
    "typing",
}

_DISALLOWED_CALLS: Set[str] = {
    "eval",
    "exec",
    "open",
    "compile",
    "__import__",
}


def _restricted_import(name: str, globals_: Any | None = None, locals_: Any | None = None, fromlist=(), level: int = 0):
    """Import hook that only allows whitelisted modules within the sandbox."""

    del globals_, locals_, level
    module_root = name.split(".")[0]
    if module_root not in _ALLOWED_IMPORT_MODULES:
        raise ImportError(f"Import of module '{name}' is not permitted in sandboxed execution.")
    return __import__(name, None, None, fromlist)


def _build_exec_globals() -> Dict[str, Any]:
    """Construct the sandboxed globals mapping for executing patched code."""

    safe_builtins = dict(_BASE_SAFE_BUILTINS)
    safe_builtins["__import__"] = _restricted_import
    return {
        "__builtins__": MappingProxyType(safe_builtins),
        "__name__": "__sandbox__",
        "__package__": None,
    }


def _string_from_node(node: ast.AST) -> str | None:
    """Return string value from AST nodes where applicable."""

    if isinstance(node, ast.Constant) and isinstance(node.value, str):
        return node.value
    if isinstance(node, ast.JoinedStr):
        literal_parts = [part.value for part in node.values if isinstance(part, ast.Constant)]
        if literal_parts:
            return "".join(literal_parts)
    return None


def _binop_contains_sql_concatenation(node: ast.BinOp) -> bool:
    """Check whether a BinOp tree concatenates SQL literals with non-literal expressions."""

    if not isinstance(node.op, ast.Add):
        return False

    contains_sql_literal = False
    contains_dynamic = False

    def _walk(sub_node: ast.AST) -> None:
        nonlocal contains_sql_literal, contains_dynamic
        if isinstance(sub_node, ast.BinOp) and isinstance(sub_node.op, ast.Add):
            _walk(sub_node.left)
            _walk(sub_node.right)
            return

        literal = _string_from_node(sub_node)
        if literal is not None:
            if "select" in literal.lower():
                contains_sql_literal = True
        else:
            if not (isinstance(sub_node, ast.Constant) and isinstance(getattr(sub_node, "value", None), str)):
                contains_dynamic = True

    _walk(node)
    return contains_sql_literal and contains_dynamic


def apply_unified_diff(original: str, diff: str) -> Optional[str]:
    """Apply a unified diff string to the original code using a vetted parser."""

    if not diff.strip():
        return original

    try:
        patch = PatchSet.from_string(diff)
    except (UnidiffParseError, TypeError):
        return None

    if len(patch) != 1:
        return None

    patched_file = patch[0]

    original_lines = original.splitlines()
    patched_lines: List[str] = []
    original_index = 0

    for hunk in patched_file:
        hunk_start = max(hunk.source_start - 1, 0)
        if hunk_start > len(original_lines):
            return None

        patched_lines.extend(original_lines[original_index:hunk_start])
        original_index = hunk_start

        for line in hunk:
            if line.line_type == "\\":
                continue

            value = line.value.rstrip("\n")

            if line.is_context:
                if original_index >= len(original_lines) or original_lines[original_index] != value:
                    return None
                patched_lines.append(value)
                original_index += 1
            elif line.is_removed:
                if original_index >= len(original_lines) or original_lines[original_index] != value:
                    return None
                original_index += 1
            elif line.is_added:
                patched_lines.append(value)

    patched_lines.extend(original_lines[original_index:])

    return "\n".join(patched_lines)


def _normalize_query_result(result: Any) -> Any:
    """Normalize SQL query return values to comparable dictionaries."""

    if isinstance(result, dict) and "query" in result:
        params = result.get("params", ())
        if isinstance(params, list):
            params = tuple(params)
        elif not isinstance(params, tuple):
            params = (params,)
        return {"query": result["query"], "params": tuple(params)}

    if isinstance(result, tuple) and len(result) == 2:
        query, params = result
        if isinstance(params, list):
            params = tuple(params)
        elif not isinstance(params, tuple):
            params = (params,)
        return {"query": query, "params": tuple(params)}

    return result


def _validate_patched_code(patched_code: str) -> None:
    """Ensure patched code obeys sandbox constraints before execution."""

    try:
        tree = ast.parse(patched_code)
    except SyntaxError as exc:  # pragma: no cover - invalid syntax handled elsewhere
        raise ValueError(f"Patched code is not valid Python: {exc.msg}") from exc

    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                module_root = alias.name.split(".")[0]
                if module_root not in _ALLOWED_IMPORT_MODULES:
                    raise ValueError(f"Import of module '{alias.name}' is not permitted in sandboxed execution.")
        elif isinstance(node, ast.ImportFrom):
            module = node.module or ""
            module_root = module.split(".")[0]
            if module_root not in _ALLOWED_IMPORT_MODULES:
                module_name = module or "<relative>"
                raise ValueError(
                    f"Import from module '{module_name}' is not permitted in sandboxed execution."
                )
        elif isinstance(node, ast.Call):
            if isinstance(node.func, ast.Name) and node.func.id in _DISALLOWED_CALLS:
                raise ValueError(f"Call to '{node.func.id}' is not permitted in sandboxed execution.")


def _detect_sql_injection_patterns(code: str) -> Optional[str]:
    """Return a descriptive finding if SQL string concatenation patterns are detected."""

    try:
        tree = ast.parse(code)
    except SyntaxError:
        code_lower = code.lower()
        if "select" in code_lower and (".format" in code_lower or "%" in code or "{" in code and "}" in code):
            return "SQL injection risk: query string appears to interpolate user-controlled data."
        return None

    for node in ast.walk(tree):
        if isinstance(node, ast.BinOp) and _binop_contains_sql_concatenation(node):
            return "SQL injection risk: query string uses string concatenation without parameters."
        elif isinstance(node, ast.BinOp) and isinstance(node.op, ast.Mod):
            left_literal = _string_from_node(node.left)
            if left_literal and "select" in left_literal.lower():
                return "SQL injection risk: query string uses printf-style formatting without parameters."
        elif isinstance(node, ast.JoinedStr):
            literal = _string_from_node(node)
            has_formatted = any(isinstance(part, ast.FormattedValue) for part in node.values)
            if literal and "select" in literal.lower() and has_formatted:
                return "SQL injection risk: query constructed via f-string interpolation."
        elif isinstance(node, ast.Call):
            if isinstance(node.func, ast.Attribute) and node.func.attr == "format":
                literal = _string_from_node(node.func.value)
                if literal and "select" in literal.lower() and node.args:
                    return "SQL injection risk: query string uses str.format without parameters."

    return None


def _execute_behavioral_test(func: Any, case: Dict[str, Any], category: str, failures: List[str]) -> None:
    args = case.get("args", [])
    kwargs = case.get("kwargs", {})

    expected = case.get("expected")
    expects_exception = case.get("raises", False)

    if expects_exception:
        try:
            func(*args, **kwargs)
        except Exception as exc:  # noqa: BLE001 - inspect to re-raise unexpected issues
            expected_exceptions = (
                ImportError,
                NameError,
                TypeError,
                ValueError,
                AssertionError,
            )
            if isinstance(exc, expected_exceptions):
                return
            raise RuntimeError(
                f"Unexpected exception {exc.__class__.__name__} during test execution for {category} "
                f"with input {args}: {exc}"
            ) from exc
        failures.append(f"{category}: expected an exception for input {args} but none was raised.")
        return

    try:
        result = func(*args, **kwargs)
    except Exception as exc:  # noqa: BLE001 - we record context for the caller
        failures.append(f"{category}: call with {args} raised {exc.__class__.__name__}: {exc}")
        return

    if expected is not None:
        normalized_expected = _normalize_query_result(expected)
        normalized_result = _normalize_query_result(result)
        if normalized_expected != normalized_result:
            failures.append(f"{category}: expected {normalized_expected} but received {normalized_result}")


def _check_code_properties(patched_code: str, spec: Dict[str, Any], failures: List[str]) -> None:
    for substring in spec.get("required_substrings_in_code", []):
        if substring not in patched_code:
            if substring == "?":
                failures.append("Patched code missing required '?' placeholder for parameterized queries.")
            else:
                failures.append(f"Patched code missing required token '{substring}'.")

    for substring in spec.get("forbidden_substrings_in_code", []):
        if substring in patched_code:
            failures.append(f"Patched code still contains forbidden token '{substring}'.")


class PatchTestResult(TypedDict):
    """Structured output for the patch-and-test tool."""

    patched_code: str
    tests_passed: bool
    failures: List[str]
    details: List[str]


def run_patch_and_tests(
    *,
    original_code: str,
    diff: str | None = None,
    patched_code: str | None = None,
    test_spec: str | None = None,
) -> PatchTestResult:
    """Apply a candidate patch and execute the behavioral/security tests."""

    spec_dict: Dict[str, Any] | None

    if isinstance(test_spec, dict):
        spec_dict = test_spec
    elif isinstance(test_spec, str) and test_spec.strip():
        try:
            spec_dict = json.loads(test_spec)
        except json.JSONDecodeError:
            spec_dict = None
    else:
        spec_dict = None

    if patched_code is None:
        patched_code = apply_unified_diff(original_code, diff or "")

    if patched_code is None:
        return {
            "patched_code": original_code,
            "tests_passed": False,
            "failures": ["Failed to apply diff to original code."],
            "details": [],
        }

    if not spec_dict:
        return {
            "patched_code": patched_code,
            "tests_passed": False,
            "failures": ["No test specification provided."],
            "details": [],
        }

    try:
        _validate_patched_code(patched_code)
    except ValueError as exc:
        return {
            "patched_code": patched_code,
            "tests_passed": False,
            "failures": [str(exc)],
            "details": [],
        }

    exec_globals = _build_exec_globals()

    try:
        code_obj = compile(patched_code, "<patched_code>", "exec")
    except SyntaxError as exc:
        return {
            "patched_code": patched_code,
            "tests_passed": False,
            "failures": [f"Patched code failed to compile: {exc.msg}"],
            "details": [],
        }

    try:
        exec(code_obj, exec_globals)  # noqa: S102 - deliberate execution of trusted dataset code
    except Exception as exc:  # noqa: BLE001 - sandbox errors surfaced to caller
        return {
            "patched_code": patched_code,
            "tests_passed": False,
            "failures": [f"Patched code raised {exc.__class__.__name__}: {exc}"],
            "details": [],
        }

    entrypoint = spec_dict.get("entrypoint")
    func = exec_globals.get(entrypoint)

    if not callable(func):
        return {
            "patched_code": patched_code,
            "tests_passed": False,
            "failures": [f"Entrypoint '{entrypoint}' is not callable in patched code."],
            "details": [],
        }

    failures: List[str] = []

    for case in spec_dict.get("behavioral_tests", []):
        try:
            _execute_behavioral_test(func, case, "Behavioral", failures)
        except RuntimeError as exc:  # Surface unexpected sandbox errors to the caller
            failures.append(str(exc))

    for case in spec_dict.get("security_tests", []):
        try:
            _execute_behavioral_test(func, case, "Security", failures)
        except RuntimeError as exc:
            failures.append(str(exc))

    _check_code_properties(patched_code, spec_dict, failures)

    return {
        "patched_code": patched_code,
        "tests_passed": not failures,
        "failures": failures,
        "details": [],
    }


def run_python_static_scan(code: str) -> Dict[str, Any]:
    """Simple heuristic static analysis for Python snippets."""

    vulnerabilities: List[str] = []

    sql_issue = _detect_sql_injection_patterns(code)
    if sql_issue:
        vulnerabilities.append(sql_issue)

    code_lower = code.lower()

    if "yaml.load" in code_lower and "safe_load" not in code_lower:
        vulnerabilities.append("Unsafe YAML loading: yaml.load without SafeLoader exposes arbitrary object execution.")

    if "random" in code_lower and "token" in code_lower and "secrets" not in code_lower:
        vulnerabilities.append("Insecure randomness: prefer secrets.token_hex for security tokens.")

    return {
        "language": "python",
        "vulnerabilities_found": len(vulnerabilities),
        "vulnerabilities": vulnerabilities,
        "verdict": "Vulnerable" if vulnerabilities else "Secure",
    }


class CodeVulnerabilityParser(vf.Parser):
    """Parser for JSON-structured vulnerability repair outputs."""

    def parse_answer(self, completion: Any) -> Dict[str, Any]:
        text = get_response_text(completion)
        try:
            data = json.loads(text)
        except json.JSONDecodeError:
            return {}

        return {
            "diff": str(data.get("diff", "")),
            "tests_passed": bool(data.get("tests_passed", False)),
            "explanation": str(data.get("explanation", "")),
            "patched_code": str(data.get("patched_code", "")),
        }

    def get_format_reward_func(self):
        required_keys = {"diff", "tests_passed", "explanation"}

        def format_reward(completion, answer="", **_kwargs):  # pylint: disable=unused-argument
            text = get_response_text(completion)
            try:
                data = json.loads(text)
            except json.JSONDecodeError:
                return 0.0

            if not required_keys.issubset(data):
                return 0.0

            if not isinstance(data.get("tests_passed"), bool):
                return 0.5

            explanation = str(data.get("explanation", ""))
            return 1.0 if explanation.strip() else 0.5

        return format_reward


def reward_patch_and_test(
    completion,
    answer: Dict[str, Any] | None = None,
    tools_used: Iterable[str] | None = None,  # noqa: ARG001 - part of ToolEnv interface
    **_kwargs,
) -> float:
    """Reward function combining tests, diff similarity, and explanation quality."""

    del tools_used

    if not answer:
        return 0.0

    text = get_response_text(completion)
    try:
        data = json.loads(text)
    except json.JSONDecodeError:
        return 0.0

    diff = str(data.get("diff", ""))
    claimed_tests_passed = bool(data.get("tests_passed", False))
    explanation = str(data.get("explanation", ""))
    patched_code = data.get("patched_code")

    original_code = answer.get("original_code", "")
    expected_diff = answer.get("expected_diff", "")
    test_spec = answer.get("test_spec", {})
    keywords = answer.get("explanation_keywords", [])

    if isinstance(patched_code, str) and patched_code.strip():
        candidate_code = patched_code
        patch_result = run_patch_and_tests(
            original_code=original_code,
            patched_code=candidate_code,
            test_spec=json.dumps(test_spec),
        )
    else:
        patch_result = run_patch_and_tests(
            original_code=original_code,
            diff=diff,
            test_spec=json.dumps(test_spec),
        )
        candidate_code = patch_result.get("patched_code", "")

    actual_tests_passed = bool(patch_result.get("tests_passed", False))

    tests_score = 1.0 if actual_tests_passed else 0.0
    consistency_score = 1.0 if actual_tests_passed == claimed_tests_passed else 0.0

    if expected_diff and diff:
        diff_similarity = SequenceMatcher(None, expected_diff.strip(), diff.strip()).ratio()
    elif expected_diff:
        diff_similarity = 0.0
    else:
        diff_similarity = 1.0

    if keywords:
        explanation_lower = explanation.lower()
        matches = sum(1 for kw in keywords if kw.lower() in explanation_lower)
        explanation_score = matches / len(keywords)
    else:
        explanation_score = 1.0 if explanation.strip() else 0.0

    base_reward = 0.6 * tests_score + 0.2 * diff_similarity + 0.1 * consistency_score + 0.1 * explanation_score

    if not actual_tests_passed and patch_result.get("failures"):
        base_reward = max(0.0, base_reward - 0.1)

    return min(base_reward, 1.0)


@dataclass
class DatasetExample:
    """Simple container for dataset entries."""

    question: str
    answer: Dict[str, Any]


def _build_sql_injection_example() -> DatasetExample:
    vulnerable_code = textwrap.dedent(
        '''
        def build_query(username: str) -> str:
            """Return a SQL query for the supplied username."""

            return f"SELECT * FROM users WHERE name = '{username}'"
        '''
    ).strip()

    patched_code = textwrap.dedent(
        '''
        def build_query(username: str) -> tuple[str, tuple[str, ...]]:
            """Return a parameterized SQL query and parameters."""

            query = "SELECT * FROM users WHERE name = ?"
            params = (username,)
            return query, params
        '''
    ).strip()

    diff = "\n".join(
        unified_diff(
            vulnerable_code.splitlines(),
            patched_code.splitlines(),
            fromfile="query.py",
            tofile="query.py",
            lineterm="",
        )
    )

    question = textwrap.dedent(
        f"""
        You are securing a Python helper that builds SQL queries. Patch the vulnerability and
        return JSON with fields "diff", "tests_passed", "explanation", and optional "patched_code".

        Vulnerable implementation:
        ```python
        {vulnerable_code}
        ```

        Requirements:
        - Return a parameterized query string alongside a tuple of parameters.
        - Ensure suspicious usernames do not appear directly embedded in the SQL string.
        - Keep the function signature unchanged.
        """
    ).strip()

    answer = {
        "id": "sql_injection_parameterization",
        "language": "python",
        "original_code": vulnerable_code,
        "patched_code": patched_code,
        "expected_diff": diff,
        "test_spec": {
            "entrypoint": "build_query",
            "behavioral_tests": [
                {
                    "args": ["alice"],
                    "expected": {
                        "query": "SELECT * FROM users WHERE name = ?",
                        "params": ("alice",),
                    },
                }
            ],
            "security_tests": [
                {
                    "args": ["bob' OR '1'='1"],
                    "expected": {
                        "query": "SELECT * FROM users WHERE name = ?",
                        "params": ("bob' OR '1'='1",),
                    },
                }
            ],
            "required_substrings_in_code": ["?"],
            "forbidden_substrings_in_code": ["%", "+"],
        },
        "expected_tests_passed": True,
        "explanation_keywords": ["parameterized", "parameters"],
    }

    return DatasetExample(question=question, answer=answer)


def _build_yaml_example() -> DatasetExample:
    vulnerable_code = textwrap.dedent(
        '''
        import yaml


        def load_config(document: str):
            """Load YAML configuration without safety checks."""

            return yaml.load(document, Loader=yaml.FullLoader)
        '''
    ).strip()

    patched_code = textwrap.dedent(
        '''
        import yaml


        def load_config(document: str):
            """Safely load YAML configuration using safe_load."""

            return yaml.safe_load(document)
        '''
    ).strip()

    diff = "\n".join(
        unified_diff(
            vulnerable_code.splitlines(),
            patched_code.splitlines(),
            fromfile="config.py",
            tofile="config.py",
            lineterm="",
        )
    )

    question = textwrap.dedent(
        f"""
        Harden the YAML loader below. Replace the unsafe behaviour and report the diff along with
        whether the provided regression tests pass.

        ```python
        {vulnerable_code}
        ```

        Security expectations:
        - Use a safe loader that prevents arbitrary object construction.
        - Benign configuration strings should still parse into Python dictionaries.
        - Malicious payloads such as ``!!python/object/apply`` must raise an exception.
        """
    ).strip()

    answer = {
        "id": "yaml_safe_load",
        "language": "python",
        "original_code": vulnerable_code,
        "patched_code": patched_code,
        "expected_diff": diff,
        "test_spec": {
            "entrypoint": "load_config",
            "behavioral_tests": [
                {
                    "args": ["debug: false"],
                    "expected": {"debug": False},
                }
            ],
            "security_tests": [
                {
                    "args": ["!!python/object/apply:os.system ['echo unsafe']"],
                    "raises": True,
                }
            ],
            "required_substrings_in_code": ["safe_load"],
            "forbidden_substrings_in_code": ["yaml.load"],
        },
        "expected_tests_passed": True,
        "explanation_keywords": ["safe_load", "unsafe", "yaml"],
    }

    return DatasetExample(question=question, answer=answer)


def _build_dataset(max_examples: int | None = None) -> Dataset:
    examples = [_build_sql_injection_example(), _build_yaml_example()]

    if max_examples is not None:
        examples = examples[:max_examples]

    dataset_dicts = [{"question": example.question, "answer": example.answer} for example in examples]

    return Dataset.from_list(dataset_dicts)


def load_environment(
    dataset_name: str | None = None,
    max_examples: int | None = None,
    logger: RolloutLogger | None = None,
) -> vf.ToolEnv:
    """Load the vulnerability repair environment as a ToolEnv."""

    del dataset_name

    dataset = _build_dataset(max_examples)
    parser = CodeVulnerabilityParser()

    rubric = vf.Rubric(
        funcs=[
            reward_patch_and_test,
            parser.get_format_reward_func(),
        ],
        weights=[1.0, 0.2],
    )

    if logger and logger.enabled:
        logger.log_environment_init(
            environment_name="sv-env-code-vulnerability",
            dataset_name="synthetic",
            total_examples=len(dataset),
            metadata={"max_examples": max_examples},
        )

    return vf.ToolEnv(
        name="sv-env-code-vulnerability",
        description=(
            "Repair vulnerable Python snippets by producing unified diff patches and running regression tests."
        ),
        dataset=dataset,
        parser=parser,
        rubric=rubric,
        tools=[run_python_static_scan, run_patch_and_tests],
        system_prompt=textwrap.dedent(
            """
            You are a secure code maintainer. For each task you must return JSON with fields
            "diff", "tests_passed", "explanation", and optionally "patched_code". Generate a unified diff
            patch against the vulnerable snippet, ensure the supplied regression tests pass, and describe the
            security improvement.
            """
        ).strip(),
    )


__all__ = [
    "CodeVulnerabilityParser",
    "apply_unified_diff",
    "load_environment",
    "reward_patch_and_test",
    "run_patch_and_tests",
    "run_python_static_scan",
]
