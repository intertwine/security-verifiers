"""sv_env_code_vulnerability: Security Verifiers environment for Code Vulnerability Assessment.

This package implements PRD Environment #5: A ToolEnv/MultiTurnEnv where models inspect
source code for security vulnerabilities and suggest fixes. The model can call static
analysis functions and propose corrected code snippets.
"""

from __future__ import annotations

from typing import Any, Dict

from pathlib import Path
import sys

sys.path.append(str(Path(__file__).resolve().parents[2]))

import verifiers as vf
from datasets import Dataset

from security_verifiers.utils import RolloutLogger


class CodeVulnerabilityParser(vf.Parser):
    """Parser to extract vulnerability findings and fixes from model responses."""

    def parse_answer(self, completion: str) -> str:
        """Extract vulnerability detection and fix from the response.

        Args:
            completion: The raw model completion/response.

        Returns:
            The extracted vulnerability assessment.
        """
        # Clean and normalize the response
        cleaned = completion.strip().lower()

        # Look for vulnerability indicators
        # Check "fixed" before "vulnerability"
        if "fixed" in cleaned or "has been fixed" in cleaned:
            return "Fixed"
        if "vulnerable" in cleaned or "vulnerability" in cleaned:
            return "Vulnerable"
        if "secure" in cleaned and "insecure" not in cleaned:
            return "Secure"

        # Return original if no clear assessment found
        return completion.strip()

    def get_format_reward_func(self):
        """Return a format reward function that checks for proper vulnerability report format."""

        def format_reward(
            completion,
            answer="",  # pylint: disable=unused-argument
            **kwargs,  # pylint: disable=unused-argument
        ):
            """Reward proper vulnerability analysis format."""
            # Extract response text from completion
            if isinstance(completion, list):
                response = completion[-1]["content"] if completion else ""
            else:
                response = str(completion)

            cleaned = response.strip().lower()

            # Perfect format: identifies vulnerability and provides fix
            if any(v in cleaned for v in ["vulnerable", "vulnerability", "issue", "problem"]) and any(  # pylint: disable=line-too-long
                f in cleaned for f in ["fix", "corrected", "secure version", "should be"]
            ):
                return 1.0

            # Good format: identifies issue but no fix
            if any(v in cleaned for v in ["vulnerable", "vulnerability", "secure", "issue"]):
                return 0.5

            # Poor format: no clear analysis
            return 0.0

        return format_reward


def scan_python_code(code: str) -> Dict[str, Any]:
    """Tool function to scan Python code for common vulnerabilities.

    Args:
        code: Python source code to analyze.

    Returns:
        Dictionary containing scan results and detected vulnerabilities.
    """
    vulnerabilities = []
    severity_scores = []

    code_lower = code.lower()

    # Check for common Python vulnerabilities
    if "eval(" in code:
        vulnerabilities.append("Use of eval() - code injection risk")
        severity_scores.append(9)

    if "exec(" in code:
        vulnerabilities.append("Use of exec() - code execution vulnerability")
        severity_scores.append(9)

    if "pickle.loads" in code:
        vulnerabilities.append("Unsafe pickle deserialization - remote code execution")
        severity_scores.append(8)

    if "os.system" in code or "subprocess.call" in code:
        if "shell=true" in code_lower.replace(" ", ""):
            vulnerabilities.append("Command injection via shell=True")
            severity_scores.append(9)

    if "sql" in code_lower and ("%s" in code or "format(" in code or "+" in code):
        vulnerabilities.append("Potential SQL injection - use parameterized queries")
        severity_scores.append(8)

    if "random.random" in code and ("password" in code_lower or "token" in code_lower):
        vulnerabilities.append("Weak random number generation for security tokens")
        severity_scores.append(6)

    if "md5" in code_lower or "sha1" in code_lower:
        vulnerabilities.append("Use of weak cryptographic hash function")
        severity_scores.append(5)

    max_severity = max(severity_scores) if severity_scores else 0

    return {
        "language": "Python",
        "vulnerabilities_found": len(vulnerabilities),
        "vulnerabilities": vulnerabilities,
        "max_severity": max_severity,
        "verdict": "Vulnerable" if vulnerabilities else "Secure",
    }


def scan_c_code(code: str) -> Dict[str, Any]:
    """Tool function to scan C/C++ code for common vulnerabilities.

    Args:
        code: C/C++ source code to analyze.

    Returns:
        Dictionary containing scan results and detected vulnerabilities.
    """
    vulnerabilities = []
    severity_scores = []

    # Check for common C/C++ vulnerabilities
    if "gets(" in code:
        vulnerabilities.append("Use of gets() - buffer overflow vulnerability")
        severity_scores.append(10)

    if "strcpy(" in code:
        vulnerabilities.append("Use of strcpy() - potential buffer overflow")
        severity_scores.append(8)

    if "strcat(" in code:
        vulnerabilities.append("Use of strcat() - potential buffer overflow")
        severity_scores.append(8)

    if "sprintf(" in code:
        vulnerabilities.append("Use of sprintf() - format string vulnerability")
        severity_scores.append(7)

    if 'scanf("%s' in code:
        vulnerabilities.append("Unsafe scanf() usage - buffer overflow risk")
        severity_scores.append(8)

    if "system(" in code:
        vulnerabilities.append("Use of system() - command injection risk")
        severity_scores.append(9)

    if "rand()" in code and "seed" not in code.lower():
        vulnerabilities.append("Weak random number generation")
        severity_scores.append(5)

    max_severity = max(severity_scores) if severity_scores else 0

    return {
        "language": "C/C++",
        "vulnerabilities_found": len(vulnerabilities),
        "vulnerabilities": vulnerabilities,
        "max_severity": max_severity,
        "verdict": "Vulnerable" if vulnerabilities else "Secure",
    }


def reward_vulnerability_detection(
    completion,
    answer: str = "",
    tools_used: list | None = None,
    **kwargs,  # pylint: disable=unused-argument
) -> float:
    """Reward function for successful vulnerability detection and fixing.

    Args:
        completion: The model's response with vulnerability analysis.
        answer: The ground truth vulnerabilities from the dataset.
        tools_used: List of analysis tools used.
        **kwargs: Additional arguments.

    Returns:
        Reward based on detection accuracy and fix quality.
    """
    # Extract the response text from completion
    if isinstance(completion, list):
        response = completion[-1]["content"] if completion else ""
    else:
        response = str(completion)

    response_lower = response.lower()

    # Bonus for using analysis tools
    tool_bonus = 0.2 if tools_used else 0.0

    if not answer:
        return 0.0 + tool_bonus

    answer_lower = answer.lower()

    # Check if vulnerabilities were correctly identified
    detection_score = 0.0
    if "vulnerable" in answer_lower:
        if "vulnerable" in response_lower or "vulnerability" in response_lower:
            detection_score = 0.5
    elif "secure" in answer_lower:
        if "secure" in response_lower and "vulnerable" not in response_lower:
            detection_score = 0.5

    # Check if fix was provided when needed
    fix_score = 0.0
    if "vulnerable" in answer_lower:
        if any(word in response_lower for word in ["fix", "should use", "instead", "corrected"]):
            fix_score = 0.5

    return min(1.0, detection_score + fix_score + tool_bonus)


def load_environment(
    dataset_name: str = "synthetic",  # pylint: disable=unused-argument
    max_examples: int = 100,
    logger: RolloutLogger | None = None,
) -> vf.ToolEnv:
    """Load the Code Vulnerability Assessment environment.

    This environment is a tool-enabled task where the model inspects source code
    for security vulnerabilities and suggests fixes.

    Args:
        dataset_name: Dataset name (currently only synthetic supported).
        max_examples: Maximum number of examples to use.
        logger: Optional rollout logger capturing dataset metadata.

    Returns:
        A Verifiers ToolEnv configured for the task.
    """

    def _create_synthetic_dataset():
        """Create a synthetic dataset of vulnerable code snippets."""
        examples = []

        # pylint: disable=line-too-long
        code_examples = [
            # Python vulnerabilities
            {
                "question": (
                    "Analyze this Python code for vulnerabilities:\n"
                    "```python\n"
                    "def process_input(user_input):\n"
                    "    result = eval(user_input)\n"
                    "    return result\n"
                    "```"
                ),
                "answer": "Vulnerable: eval() allows arbitrary code execution",
                "language": "python",
            },
            {
                "question": (
                    "Review this Python code:\n"
                    "```python\n"
                    "import subprocess\n"
                    "def run_command(cmd):\n"
                    "    subprocess.call(cmd, shell=True)\n"
                    "```"
                ),
                "answer": "Vulnerable: shell=True enables command injection",
                "language": "python",
            },
            {
                "question": (
                    "Check this Python code:\n"
                    "```python\n"
                    "import hashlib\n"
                    "def hash_password(password):\n"
                    "    return hashlib.sha256(password.encode()).hexdigest()\n"
                    "```"
                ),
                "answer": "Secure",
                "language": "python",
            },
            # C/C++ vulnerabilities
            {
                "question": (
                    "Analyze this C code:\n"
                    "```c\n"
                    "void read_input() {\n"
                    "    char buffer[100];\n"
                    "    gets(buffer);\n"
                    '    printf("You entered: %s\\n", buffer);\n'
                    "}\n"
                    "```"
                ),
                "answer": "Vulnerable: gets() causes buffer overflow",
                "language": "c",
            },
            {
                "question": (
                    "Review this C code:\n"
                    "```c\n"
                    "void copy_string(char *dest, char *src) {\n"
                    "    strcpy(dest, src);\n"
                    "}\n"
                    "```"
                ),
                "answer": "Vulnerable: strcpy() can overflow destination buffer",
                "language": "c",
            },
            {
                "question": (
                    "Check this C code:\n"
                    "```c\n"
                    "void safe_copy(char *dest, char *src, size_t n) {\n"
                    "    strncpy(dest, src, n-1);\n"
                    "    dest[n-1] = '\\0';\n"
                    "}\n"
                    "```"
                ),
                "answer": "Secure",
                "language": "c",
            },
            # SQL injection examples
            {
                "question": (
                    "Analyze this Python database code:\n"
                    "```python\n"
                    "def get_user(username):\n"
                    '    query = "SELECT * FROM users WHERE name = \'" + username + "\'"\n'
                    "    cursor.execute(query)\n"
                    "```"
                ),
                "answer": "Vulnerable: SQL injection via string concatenation",
                "language": "python",
            },
            {
                "question": (
                    "Review this code:\n"
                    "```python\n"
                    "def get_user_safe(username):\n"
                    '    query = "SELECT * FROM users WHERE name = ?"\n'
                    "    cursor.execute(query, (username,))\n"
                    "```"
                ),
                "answer": "Secure",
                "language": "python",
            },
            # Cryptography issues
            {
                "question": (
                    "Check this encryption code:\n"
                    "```python\n"
                    "import random\n"
                    "def generate_token():\n"
                    "    return str(random.random())\n"
                    "```"
                ),
                "answer": "Vulnerable: weak random number generation for tokens",
                "language": "python",
            },
            {
                "question": (
                    "Analyze this code:\n"
                    "```python\n"
                    "import secrets\n"
                    "def generate_secure_token():\n"
                    "    return secrets.token_hex(32)\n"
                    "```"
                ),
                "answer": "Secure",
                "language": "python",
            },
        ]
        # pylint: enable=line-too-long

        examples.extend(code_examples[:max_examples] if max_examples else code_examples)
        return Dataset.from_list(examples)

    dataset = _create_synthetic_dataset()

    parser = CodeVulnerabilityParser()

    # Define code analysis tools
    tools = [
        scan_python_code,
        scan_c_code,
    ]

    rubric = vf.Rubric(
        funcs=[
            reward_vulnerability_detection,
            parser.get_format_reward_func(),
        ],
        weights=[1.0, 0.3],  # Detection/fix accuracy is primary
    )

    if logger and logger.enabled:
        logger.log_environment_init(
            environment_name="sv-env-code-vulnerability",
            dataset_name=dataset_name,
            total_examples=len(dataset),
            metadata={"max_examples": max_examples},
        )

    return vf.ToolEnv(
        name="sv-env-code-vulnerability",
        description=("Inspect source code for security vulnerabilities and suggest fixes."),
        dataset=dataset,
        parser=parser,
        rubric=rubric,
        tools=tools,
        system_prompt=(
            "You are a code security analyst. Inspect the provided source code for security "
            "vulnerabilities. Use the available scanning tools when appropriate. If vulnerabilities "  # pylint: disable=line-too-long
            "are found, explain them clearly and provide secure alternatives or fixes."
        ),
    )
