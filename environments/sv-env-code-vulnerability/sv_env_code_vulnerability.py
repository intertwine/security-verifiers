"""Security Verifiers environment: code vulnerability repair with patch-and-test."""

from __future__ import annotations

import json
import textwrap
from dataclasses import dataclass
from difflib import SequenceMatcher, unified_diff
from pathlib import Path
import sys
from typing import Any, Dict, Iterable, List, Optional
from typing_extensions import TypedDict

import verifiers as vf
from datasets import Dataset

# Allow importing shared utilities when running from the repo root.
sys.path.append(str(Path(__file__).resolve().parents[2]))

from sv_shared import RolloutLogger, get_response_text  # type: ignore  # pylint: disable=wrong-import-position


_SAFE_BUILTINS: Dict[str, Any] = {
    "__import__": __import__,
    "abs": abs,
    "all": all,
    "any": any,
    "bool": bool,
    "dict": dict,
    "enumerate": enumerate,
    "float": float,
    "int": int,
    "len": len,
    "list": list,
    "max": max,
    "min": min,
    "range": range,
    "set": set,
    "sorted": sorted,
    "str": str,
    "sum": sum,
    "tuple": tuple,
    "zip": zip,
}


def apply_unified_diff(original: str, diff: str) -> Optional[str]:
    """Apply a unified diff string to the original code."""

    if not diff.strip():
        return original

    original_lines = original.splitlines()
    diff_lines = diff.splitlines()
    patched_lines: List[str] = []
    original_index = 0

    def flush_until(target_index: int) -> None:
        nonlocal original_index
        while original_index < min(target_index, len(original_lines)):
            patched_lines.append(original_lines[original_index])
            original_index += 1

    for line in diff_lines:
        if line.startswith("---") or line.startswith("+++"):
            continue
        if line.startswith("@@"):
            # Unified diff hunk header format: '@@ -start,count +start,count @@'
            try:
                _, old_line_range, _ = line.split(" ")[:3]
                old_start = int(old_line_range.split(",")[0][1:]) - 1
            except (ValueError, IndexError):
                return None
            flush_until(old_start)
            continue
        if line.startswith("-"):
            original_index += 1
            continue
        if line.startswith("+"):
            patched_lines.append(line[1:])
            continue
        if line.startswith(" "):
            if original_index >= len(original_lines):
                return None
            patched_lines.append(original_lines[original_index])
            original_index += 1
    flush_until(len(original_lines))

    return "\n".join(patched_lines)


def _normalize_query_result(result: Any) -> Any:
    """Normalize SQL query return values to comparable dictionaries."""

    if isinstance(result, dict) and "query" in result:
        params = result.get("params", ())
        if isinstance(params, list):
            params = tuple(params)
        elif not isinstance(params, tuple):
            params = (params,)
        return {"query": result["query"], "params": tuple(params)}

    if isinstance(result, tuple) and len(result) == 2:
        query, params = result
        if isinstance(params, list):
            params = tuple(params)
        elif not isinstance(params, tuple):
            params = (params,)
        return {"query": query, "params": tuple(params)}

    return result


def _execute_behavioral_test(func: Any, case: Dict[str, Any], category: str, failures: List[str]) -> None:
    args = case.get("args", [])
    kwargs = case.get("kwargs", {})

    expected = case.get("expected")
    expects_exception = case.get("raises", False)

    if expects_exception:
        try:
            func(*args, **kwargs)
        except Exception as exc:  # noqa: BLE001 - inspect to re-raise unexpected issues
            expected_exceptions = (
                ImportError,
                NameError,
                TypeError,
                ValueError,
                AssertionError,
            )
            if isinstance(exc, expected_exceptions):
                return
            raise RuntimeError(
                "Unexpected exception %s during test execution for %s with input %s: %s"
                % (exc.__class__.__name__, category, args, exc)
            ) from exc
        failures.append(f"{category}: expected an exception for input {args} but none was raised.")
        return

    try:
        result = func(*args, **kwargs)
    except Exception as exc:  # noqa: BLE001 - we record context for the caller
        failures.append(f"{category}: call with {args} raised {exc.__class__.__name__}: {exc}")
        return

    if expected is not None:
        normalized_expected = _normalize_query_result(expected)
        normalized_result = _normalize_query_result(result)
        if normalized_expected != normalized_result:
            failures.append(f"{category}: expected {normalized_expected} but received {normalized_result}")


def _check_code_properties(patched_code: str, spec: Dict[str, Any], failures: List[str]) -> None:
    for substring in spec.get("required_substrings_in_code", []):
        if substring not in patched_code:
            if substring == "?":
                failures.append("Patched code missing required '?' placeholder for parameterized queries.")
            else:
                failures.append(f"Patched code missing required token '{substring}'.")

    for substring in spec.get("forbidden_substrings_in_code", []):
        if substring in patched_code:
            failures.append(f"Patched code still contains forbidden token '{substring}'.")


class PatchTestResult(TypedDict):
    """Structured output for the patch-and-test tool."""

    patched_code: str
    tests_passed: bool
    failures: List[str]
    details: List[str]


def run_patch_and_tests(
    *,
    original_code: str,
    diff: str | None = None,
    patched_code: str | None = None,
    test_spec: str | None = None,
) -> PatchTestResult:
    """Apply a candidate patch and execute the behavioral/security tests."""

    spec_dict: Dict[str, Any] | None

    if isinstance(test_spec, dict):
        spec_dict = test_spec
    elif isinstance(test_spec, str) and test_spec.strip():
        try:
            spec_dict = json.loads(test_spec)
        except json.JSONDecodeError:
            spec_dict = None
    else:
        spec_dict = None

    if patched_code is None:
        patched_code = apply_unified_diff(original_code, diff or "")

    if patched_code is None:
        return {
            "patched_code": original_code,
            "tests_passed": False,
            "failures": ["Failed to apply diff to original code."],
            "details": [],
        }

    if not spec_dict:
        return {
            "patched_code": patched_code,
            "tests_passed": False,
            "failures": ["No test specification provided."],
            "details": [],
        }

    exec_globals: Dict[str, Any] = {"__builtins__": dict(_SAFE_BUILTINS)}
    code_obj = compile(patched_code, "<patched_code>", "exec")
    exec(code_obj, exec_globals)  # noqa: S102 - deliberate execution of trusted dataset code

    entrypoint = spec_dict.get("entrypoint")
    func = exec_globals.get(entrypoint)

    if not callable(func):
        return {
            "patched_code": patched_code,
            "tests_passed": False,
            "failures": [f"Entrypoint '{entrypoint}' is not callable in patched code."],
            "details": [],
        }

    failures: List[str] = []

    for case in spec_dict.get("behavioral_tests", []):
        try:
            _execute_behavioral_test(func, case, "Behavioral", failures)
        except RuntimeError as exc:  # Surface unexpected sandbox errors to the caller
            failures.append(str(exc))

    for case in spec_dict.get("security_tests", []):
        try:
            _execute_behavioral_test(func, case, "Security", failures)
        except RuntimeError as exc:
            failures.append(str(exc))

    _check_code_properties(patched_code, spec_dict, failures)

    return {
        "patched_code": patched_code,
        "tests_passed": not failures,
        "failures": failures,
        "details": [],
    }


def run_python_static_scan(code: str) -> Dict[str, Any]:
    """Simple heuristic static analysis for Python snippets."""

    code_lower = code.lower()
    vulnerabilities: List[str] = []

    if "select" in code_lower and (
        "%" in code or ".format" in code_lower or "{" in code and "}" in code or "+" in code_lower
    ):
        vulnerabilities.append("SQL injection risk: query string uses concatenation/formatting without parameters.")

    if "yaml.load" in code_lower and "safe_load" not in code_lower:
        vulnerabilities.append("Unsafe YAML loading: yaml.load without SafeLoader exposes arbitrary object execution.")

    if "random" in code_lower and "token" in code_lower and "secrets" not in code_lower:
        vulnerabilities.append("Insecure randomness: prefer secrets.token_hex for security tokens.")

    return {
        "language": "python",
        "vulnerabilities_found": len(vulnerabilities),
        "vulnerabilities": vulnerabilities,
        "verdict": "Vulnerable" if vulnerabilities else "Secure",
    }


class CodeVulnerabilityParser(vf.Parser):
    """Parser for JSON-structured vulnerability repair outputs."""

    def parse_answer(self, completion: Any) -> Dict[str, Any]:
        text = get_response_text(completion)
        try:
            data = json.loads(text)
        except json.JSONDecodeError:
            return {}

        return {
            "diff": str(data.get("diff", "")),
            "tests_passed": bool(data.get("tests_passed", False)),
            "explanation": str(data.get("explanation", "")),
            "patched_code": str(data.get("patched_code", "")),
        }

    def get_format_reward_func(self):
        required_keys = {"diff", "tests_passed", "explanation"}

        def format_reward(completion, answer="", **_kwargs):  # pylint: disable=unused-argument
            text = get_response_text(completion)
            try:
                data = json.loads(text)
            except json.JSONDecodeError:
                return 0.0

            if not required_keys.issubset(data):
                return 0.0

            if not isinstance(data.get("tests_passed"), bool):
                return 0.5

            explanation = str(data.get("explanation", ""))
            return 1.0 if explanation.strip() else 0.5

        return format_reward


def reward_patch_and_test(
    completion,
    answer: Dict[str, Any] | None = None,
    tools_used: Iterable[str] | None = None,  # noqa: ARG001 - part of ToolEnv interface
    **_kwargs,
) -> float:
    """Reward function combining tests, diff similarity, and explanation quality."""

    del tools_used

    if not answer:
        return 0.0

    text = get_response_text(completion)
    try:
        data = json.loads(text)
    except json.JSONDecodeError:
        return 0.0

    diff = str(data.get("diff", ""))
    claimed_tests_passed = bool(data.get("tests_passed", False))
    explanation = str(data.get("explanation", ""))
    patched_code = data.get("patched_code")

    original_code = answer.get("original_code", "")
    expected_diff = answer.get("expected_diff", "")
    test_spec = answer.get("test_spec", {})
    keywords = answer.get("explanation_keywords", [])

    if isinstance(patched_code, str) and patched_code.strip():
        candidate_code = patched_code
        patch_result = run_patch_and_tests(
            original_code=original_code,
            patched_code=candidate_code,
            test_spec=json.dumps(test_spec),
        )
    else:
        patch_result = run_patch_and_tests(
            original_code=original_code,
            diff=diff,
            test_spec=json.dumps(test_spec),
        )
        candidate_code = patch_result.get("patched_code", "")

    actual_tests_passed = bool(patch_result.get("tests_passed", False))

    tests_score = 1.0 if actual_tests_passed else 0.0
    consistency_score = 1.0 if actual_tests_passed == claimed_tests_passed else 0.0

    if expected_diff and diff:
        diff_similarity = SequenceMatcher(None, expected_diff.strip(), diff.strip()).ratio()
    elif expected_diff:
        diff_similarity = 0.0
    else:
        diff_similarity = 1.0

    if keywords:
        explanation_lower = explanation.lower()
        matches = sum(1 for kw in keywords if kw.lower() in explanation_lower)
        explanation_score = matches / len(keywords)
    else:
        explanation_score = 1.0 if explanation.strip() else 0.0

    base_reward = 0.6 * tests_score + 0.2 * diff_similarity + 0.1 * consistency_score + 0.1 * explanation_score

    if not actual_tests_passed and patch_result.get("failures"):
        base_reward = max(0.0, base_reward - 0.1)

    return min(base_reward, 1.0)


@dataclass
class DatasetExample:
    """Simple container for dataset entries."""

    question: str
    answer: Dict[str, Any]


def _build_sql_injection_example() -> DatasetExample:
    vulnerable_code = textwrap.dedent(
        '''
        def build_query(username: str) -> str:
            """Return a SQL query for the supplied username."""

            return f"SELECT * FROM users WHERE name = '{username}'"
        '''
    ).strip()

    patched_code = textwrap.dedent(
        '''
        def build_query(username: str) -> tuple[str, tuple[str, ...]]:
            """Return a parameterized SQL query and parameters."""

            query = "SELECT * FROM users WHERE name = ?"
            params = (username,)
            return query, params
        '''
    ).strip()

    diff = "\n".join(
        unified_diff(
            vulnerable_code.splitlines(),
            patched_code.splitlines(),
            fromfile="query.py",
            tofile="query.py",
            lineterm="",
        )
    )

    question = textwrap.dedent(
        f"""
        You are securing a Python helper that builds SQL queries. Patch the vulnerability and
        return JSON with fields "diff", "tests_passed", "explanation", and optional "patched_code".

        Vulnerable implementation:
        ```python
        {vulnerable_code}
        ```

        Requirements:
        - Return a parameterized query string alongside a tuple of parameters.
        - Ensure suspicious usernames do not appear directly embedded in the SQL string.
        - Keep the function signature unchanged.
        """
    ).strip()

    answer = {
        "id": "sql_injection_parameterization",
        "language": "python",
        "original_code": vulnerable_code,
        "patched_code": patched_code,
        "expected_diff": diff,
        "test_spec": {
            "entrypoint": "build_query",
            "behavioral_tests": [
                {
                    "args": ["alice"],
                    "expected": {
                        "query": "SELECT * FROM users WHERE name = ?",
                        "params": ("alice",),
                    },
                }
            ],
            "security_tests": [
                {
                    "args": ["bob' OR '1'='1"],
                    "expected": {
                        "query": "SELECT * FROM users WHERE name = ?",
                        "params": ("bob' OR '1'='1",),
                    },
                }
            ],
            "required_substrings_in_code": ["?"],
            "forbidden_substrings_in_code": ["%", "+"],
        },
        "expected_tests_passed": True,
        "explanation_keywords": ["parameterized", "parameters"],
    }

    return DatasetExample(question=question, answer=answer)


def _build_yaml_example() -> DatasetExample:
    vulnerable_code = textwrap.dedent(
        '''
        import yaml


        def load_config(document: str):
            """Load YAML configuration without safety checks."""

            return yaml.load(document, Loader=yaml.FullLoader)
        '''
    ).strip()

    patched_code = textwrap.dedent(
        '''
        import yaml


        def load_config(document: str):
            """Safely load YAML configuration using safe_load."""

            return yaml.safe_load(document)
        '''
    ).strip()

    diff = "\n".join(
        unified_diff(
            vulnerable_code.splitlines(),
            patched_code.splitlines(),
            fromfile="config.py",
            tofile="config.py",
            lineterm="",
        )
    )

    question = textwrap.dedent(
        f"""
        Harden the YAML loader below. Replace the unsafe behaviour and report the diff along with
        whether the provided regression tests pass.

        ```python
        {vulnerable_code}
        ```

        Security expectations:
        - Use a safe loader that prevents arbitrary object construction.
        - Benign configuration strings should still parse into Python dictionaries.
        - Malicious payloads such as ``!!python/object/apply`` must raise an exception.
        """
    ).strip()

    answer = {
        "id": "yaml_safe_load",
        "language": "python",
        "original_code": vulnerable_code,
        "patched_code": patched_code,
        "expected_diff": diff,
        "test_spec": {
            "entrypoint": "load_config",
            "behavioral_tests": [
                {
                    "args": ["debug: false"],
                    "expected": {"debug": False},
                }
            ],
            "security_tests": [
                {
                    "args": ["!!python/object/apply:os.system ['echo unsafe']"],
                    "raises": True,
                }
            ],
            "required_substrings_in_code": ["safe_load"],
            "forbidden_substrings_in_code": ["yaml.load"],
        },
        "expected_tests_passed": True,
        "explanation_keywords": ["safe_load", "unsafe", "yaml"],
    }

    return DatasetExample(question=question, answer=answer)


def _build_dataset(max_examples: int | None = None) -> Dataset:
    examples = [_build_sql_injection_example(), _build_yaml_example()]

    if max_examples is not None:
        examples = examples[:max_examples]

    dataset_dicts = [{"question": example.question, "answer": example.answer} for example in examples]

    return Dataset.from_list(dataset_dicts)


def load_environment(
    dataset_name: str | None = None,
    max_examples: int | None = None,
    logger: RolloutLogger | None = None,
) -> vf.ToolEnv:
    """Load the vulnerability repair environment as a ToolEnv."""

    del dataset_name

    dataset = _build_dataset(max_examples)
    parser = CodeVulnerabilityParser()

    rubric = vf.Rubric(
        funcs=[
            reward_patch_and_test,
            parser.get_format_reward_func(),
        ],
        weights=[1.0, 0.2],
    )

    if logger and logger.enabled:
        logger.log_environment_init(
            environment_name="sv-env-code-vulnerability",
            dataset_name="synthetic",
            total_examples=len(dataset),
            metadata={"max_examples": max_examples},
        )

    return vf.ToolEnv(
        name="sv-env-code-vulnerability",
        description=(
            "Repair vulnerable Python snippets by producing unified diff patches and running regression tests."
        ),
        dataset=dataset,
        parser=parser,
        rubric=rubric,
        tools=[run_python_static_scan, run_patch_and_tests],
        system_prompt=textwrap.dedent(
            """
            You are a secure code maintainer. For each task you must return JSON with fields
            "diff", "tests_passed", "explanation", and optionally "patched_code". Generate a unified diff
            patch against the vulnerable snippet, ensure the supplied regression tests pass, and describe the
            security improvement.
            """
        ).strip(),
    )


__all__ = [
    "CodeVulnerabilityParser",
    "apply_unified_diff",
    "load_environment",
    "reward_patch_and_test",
    "run_patch_and_tests",
    "run_python_static_scan",
]
