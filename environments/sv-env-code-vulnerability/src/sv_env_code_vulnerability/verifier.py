"""CodeVulnerabilityVerifier implementation for code vulnerability assessment."""

from __future__ import annotations

import ast
import re
import subprocess
import tempfile
from pathlib import Path
from typing import Any, Mapping

try:
    import bandit
    from bandit.core import config as bandit_config
    from bandit.core import manager as bandit_manager
except ImportError:
    bandit = None

from .interfaces import Verifier as VerifierProtocol


class CodeVulnerabilityVerifier(VerifierProtocol):
    """Verifier for code vulnerability assessment using static analysis tools.

    This verifier analyzes code snippets for security vulnerabilities using
    multiple approaches including AST analysis, regex patterns, and external
    tools like Bandit when available.
    """

    def __init__(self, severity_weights: dict[str, float] | None = None):
        """Initialize the code vulnerability verifier.

        Args:
            severity_weights: Weights for different vulnerability severities
                             (HIGH: 1.0, MEDIUM: 0.7, LOW: 0.4 by default)
        """
        self.severity_weights = severity_weights or {
            "HIGH": 1.0,
            "MEDIUM": 0.7,
            "LOW": 0.4
        }
        self._last_details: dict[str, Any] = {}

        # Common vulnerability patterns
        self.vulnerability_patterns = {
            "sql_injection": [
                r"execute\s*\(\s*['\"].*%.*['\"]",
                r"cursor\.execute\s*\(\s*['\"].*\+.*['\"]",
                r"query\s*=\s*['\"].*%.*['\"]",
                r"\.format\s*\(.*\)\s*['\"]",
            ],
            "command_injection": [
                r"os\.system\s*\(",
                r"subprocess\.call\s*\(",
                r"subprocess\.run\s*\(",
                r"os\.popen\s*\(",
                r"eval\s*\(",
                r"exec\s*\(",
            ],
            "path_traversal": [
                r"open\s*\(\s*.*\.\.\s*",
                r"file\s*=\s*.*\.\.\s*",
                r"\.\.\/",
                r"\.\.\\\\"
            ],
            "hardcoded_secrets": [
                r"password\s*=\s*['\"][^'\"]{8,}['\"]",
                r"secret\s*=\s*['\"][^'\"]{8,}['\"]",
                r"api_key\s*=\s*['\"][^'\"]{8,}['\"]",
                r"token\s*=\s*['\"][^'\"]{8,}['\"]",
            ],
            "unsafe_deserialization": [
                r"pickle\.loads?\s*\(",
                r"yaml\.load\s*\(",
                r"json\.loads?\s*\(",
            ],
            "weak_crypto": [
                r"md5\s*\(",
                r"sha1\s*\(",
                r"DES\s*\(",
                r"RC4\s*\(",
            ]
        }

    def score(self, code: str, execution_log: str) -> float:
        """Score code vulnerability assessment.

        Args:
            code: The source code to analyze
            execution_log: Log from code execution (for runtime analysis)

        Returns:
            float: Vulnerability score (0.0 = secure, 1.0 = highly vulnerable)
        """
        vulnerabilities = self._analyze_code(code)
        runtime_issues = self._analyze_execution_log(execution_log)

        # Calculate weighted score
        total_score = 0.0
        max_possible_score = 0.0

        for vuln in vulnerabilities + runtime_issues:
            severity = vuln.get("severity", "LOW")
            weight = self.severity_weights.get(severity, 0.4)
            total_score += weight
            max_possible_score += 1.0

        # Normalize to 0-1 range
        if max_possible_score > 0:
            normalized_score = min(1.0, total_score / max_possible_score)
        else:
            normalized_score = 0.0

        # Store details
        self._last_details = {
            "code_snippet": code[:500] + "..." if len(code) > 500 else code,
            "vulnerabilities_found": len(vulnerabilities),
            "runtime_issues_found": len(runtime_issues),
            "vulnerability_details": vulnerabilities,
            "runtime_details": runtime_issues,
            "total_score": total_score,
            "normalized_score": normalized_score,
            "severity_breakdown": self._get_severity_breakdown(vulnerabilities + runtime_issues)
        }

        return normalized_score

    def details(self) -> Mapping[str, Any]:
        """Return auxiliary information from the last verification.

        Returns:
            Mapping containing vulnerability details, scores, and analysis results
        """
        return self._last_details.copy()

    def _analyze_code(self, code: str) -> list[dict[str, Any]]:
        """Analyze code for vulnerabilities using multiple methods.

        Args:
            code: Source code to analyze

        Returns:
            List of vulnerability dictionaries
        """
        vulnerabilities = []

        # Pattern-based analysis
        vulnerabilities.extend(self._pattern_analysis(code))

        # AST-based analysis
        vulnerabilities.extend(self._ast_analysis(code))

        # Bandit analysis (if available)
        if bandit:
            vulnerabilities.extend(self._bandit_analysis(code))

        return vulnerabilities

    def _pattern_analysis(self, code: str) -> list[dict[str, Any]]:
        """Analyze code using regex patterns.

        Args:
            code: Source code to analyze

        Returns:
            List of vulnerability findings
        """
        vulnerabilities = []

        for vuln_type, patterns in self.vulnerability_patterns.items():
            for pattern in patterns:
                matches = re.finditer(pattern, code, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    line_num = code[:match.start()].count('\n') + 1
                    vulnerabilities.append({
                        "type": vuln_type,
                        "severity": self._get_pattern_severity(vuln_type),
                        "line": line_num,
                        "matched_text": match.group(),
                        "pattern": pattern,
                        "method": "pattern_analysis"
                    })

        return vulnerabilities

    def _ast_analysis(self, code: str) -> list[dict[str, Any]]:
        """Analyze code using AST parsing.

        Args:
            code: Source code to analyze

        Returns:
            List of vulnerability findings
        """
        vulnerabilities = []

        try:
            tree = ast.parse(code)

            for node in ast.walk(tree):
                # Check for dangerous function calls
                if isinstance(node, ast.Call):
                    if isinstance(node.func, ast.Name):
                        func_name = node.func.id
                        if func_name in ['eval', 'exec', 'compile']:
                            vulnerabilities.append({
                                "type": "dangerous_function",
                                "severity": "HIGH",
                                "line": getattr(node, 'lineno', 0),
                                "function": func_name,
                                "method": "ast_analysis"
                            })
                    elif isinstance(node.func, ast.Attribute):
                        if node.func.attr in ['system', 'popen'] and isinstance(node.func.value, ast.Name) and node.func.value.id == 'os':
                            vulnerabilities.append({
                                "type": "command_injection",
                                "severity": "HIGH",
                                "line": getattr(node, 'lineno', 0),
                                "function": f"os.{node.func.attr}",
                                "method": "ast_analysis"
                            })

                # Check for hardcoded strings that might be secrets
                elif isinstance(node, ast.Str) and len(node.s) > 16:
                    if any(keyword in node.s.lower() for keyword in ['password', 'secret', 'key', 'token']):
                        vulnerabilities.append({
                            "type": "potential_hardcoded_secret",
                            "severity": "MEDIUM",
                            "line": getattr(node, 'lineno', 0),
                            "method": "ast_analysis"
                        })

        except SyntaxError as e:
            vulnerabilities.append({
                "type": "syntax_error",
                "severity": "LOW",
                "line": getattr(e, 'lineno', 0),
                "message": str(e),
                "method": "ast_analysis"
            })

        return vulnerabilities

    def _bandit_analysis(self, code: str) -> list[dict[str, Any]]:
        """Analyze code using Bandit static analysis tool.

        Args:
            code: Source code to analyze

        Returns:
            List of vulnerability findings from Bandit
        """
        if not bandit:
            return []

        vulnerabilities = []

        try:
            # Create temporary file for Bandit analysis
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(code)
                temp_file = f.name

            try:
                # Configure Bandit
                conf = bandit_config.BanditConfig()
                b_mgr = bandit_manager.BanditManager(conf, 'file')

                # Run Bandit on the temporary file
                b_mgr.discover_files([temp_file])
                b_mgr.run_tests()

                # Extract findings
                for result in b_mgr.get_issue_list():
                    vulnerabilities.append({
                        "type": result.test,
                        "severity": result.severity,
                        "confidence": result.confidence,
                        "line": result.lineno,
                        "message": result.text,
                        "method": "bandit_analysis"
                    })

            finally:
                # Clean up temporary file
                Path(temp_file).unlink(missing_ok=True)

        except Exception as e:
            # If Bandit fails, add a note but don't crash
            vulnerabilities.append({
                "type": "bandit_analysis_error",
                "severity": "LOW",
                "message": f"Bandit analysis failed: {str(e)}",
                "method": "bandit_analysis"
            })

        return vulnerabilities

    def _analyze_execution_log(self, execution_log: str) -> list[dict[str, Any]]:
        """Analyze execution log for runtime security issues.

        Args:
            execution_log: Log output from code execution

        Returns:
            List of runtime issue findings
        """
        issues = []

        if not execution_log:
            return issues

        # Check for common runtime security indicators
        runtime_patterns = {
            "permission_error": r"PermissionError",
            "file_not_found": r"FileNotFoundError",
            "security_warning": r"SecurityWarning",
            "unsafe_operation": r"UnsafeOperation",
            "access_denied": r"Access.*denied",
        }

        for issue_type, pattern in runtime_patterns.items():
            matches = re.finditer(pattern, execution_log, re.IGNORECASE)
            for match in matches:
                issues.append({
                    "type": issue_type,
                    "severity": "MEDIUM",
                    "matched_text": match.group(),
                    "method": "runtime_analysis"
                })

        return issues

    def _get_pattern_severity(self, vuln_type: str) -> str:
        """Get severity level for a vulnerability type.

        Args:
            vuln_type: Type of vulnerability

        Returns:
            Severity level string
        """
        high_severity = ["sql_injection", "command_injection", "unsafe_deserialization"]
        medium_severity = ["path_traversal", "hardcoded_secrets"]

        if vuln_type in high_severity:
            return "HIGH"
        elif vuln_type in medium_severity:
            return "MEDIUM"
        else:
            return "LOW"

    def _get_severity_breakdown(self, vulnerabilities: list[dict[str, Any]]) -> dict[str, int]:
        """Get count of vulnerabilities by severity.

        Args:
            vulnerabilities: List of vulnerability findings

        Returns:
            Dictionary with severity counts
        """
        breakdown = {"HIGH": 0, "MEDIUM": 0, "LOW": 0}

        for vuln in vulnerabilities:
            severity = vuln.get("severity", "LOW")
            if severity in breakdown:
                breakdown[severity] += 1

        return breakdown

    def add_vulnerability_pattern(self, vuln_type: str, pattern: str) -> None:
        """Add a custom vulnerability pattern.

        Args:
            vuln_type: Type of vulnerability
            pattern: Regex pattern to detect the vulnerability
        """
        if vuln_type not in self.vulnerability_patterns:
            self.vulnerability_patterns[vuln_type] = []
        self.vulnerability_patterns[vuln_type].append(pattern)

    def get_supported_vulnerability_types(self) -> list[str]:
        """Get list of supported vulnerability types.

        Returns:
            List of vulnerability type names
        """
        return list(self.vulnerability_patterns.keys())
