# Vulnerability Repair in Code (Work in Progress)

Security Verifiers RL environment for **Vulnerability Repair with Patch-and-Test Loops** - implementing Environment E3 from the [PRD](../../PRD.md).

## Overview

This environment (currently in development) will implement executable vulnerability repair where models fix vulnerable code while maintaining functionality. Rewards are based on tests passing, static security improvements, and patch minimality - all verifiable through execution.

## Planned Features (Per PRD Specification)

### Input/Output Schema

- **Input**: Vulnerable code snippet + failing unit/security tests
- **Output Schema**:

```json
{
  "diff": "unified diff",
  "tests_passed": true|false,
  "explanation": "string"
}
```

### Reward Structure

- Primary: Tests must pass (functionality preserved)
- Security delta: Bandit/Semgrep warnings must decrease
- Minimality bonus: Smaller diffs preferred
- No coverage drop: Patches shouldn't reduce test coverage

### Datasets

- Devign: Function-level vulnerability detection
- Big-Vul: Real-world vulnerability patches
- Juliet Test Suite: Controlled CWE examples
- CodeXGLUE: Defect detection benchmark

## Key Innovations

1. **Executable Verification**: Not just detecting vulnerabilities but producing patches that actually work (tests pass)

2. **Multi-Objective Optimization**: Balance security fixes with functionality preservation and code minimality

3. **Iterative Refinement**: Multi-turn environment allows model to refine patches based on test results

4. **Real-World Relevance**: Training on actual CVE patches from Big-Vul dataset

## Current Status

This environment is a work in progress. The current implementation provides basic vulnerability detection as a foundation. Future development will add:

- Full test execution harness with sandboxing
- Integration with Bandit and Semgrep for security scoring
- Diff generation and validation
- Coverage tracking to ensure quality patches
- Curriculum learning from simple to complex vulnerabilities

See [PRD.md](../../PRD.md) Environment E3 for full specifications.

## Example Workflow (Target Implementation)

```text
Input: Buffer overflow in C function + unit tests
Turn 1: Model analyzes code, identifies unsafe gets()
Turn 2: Model generates patch using fgets() with bounds checking
Turn 3: Tests execute → pass ✓
Turn 4: Bandit scan → warnings reduced ✓
Output: {"diff": "...", "tests_passed": true,
         "explanation": "Replaced gets() with fgets() to prevent buffer overflow"}
Reward: 1.0 (tests pass) + 0.5 (security improved) + 0.25 (minimal diff)
```

## Structure

- `sv_env_code_vulnerability.py`: Main implementation file
- `sv_env_code_vulnerability_test.py`: Test suite

## Safety Considerations

- Sandboxed test execution to prevent malicious code
- Resource limits (CPU, memory, time) for all executions
- No network access during code evaluation
- Careful handling of dataset vulnerabilities (never execute without patches)

## Local Install (editable)

From repo root after creating a uv venv:

```bash
uv pip install -e environments/sv-env-code-vulnerability
```

## Related Work

This environment is part of the Open Security Verifiers suite. For the complete vision, see:

- [EXECUTIVE_SUMMARY.md](../../EXECUTIVE_SUMMARY.md) - Project overview
- [PRD.md](../../PRD.md) - Detailed specifications for all six environments
