# sv-env-code-vulnerability Environment Guide

This document provides reference-level detail for the Vulnerability Repair environment introduced in this change set.

## Purpose

- **Environment name**: `sv-env-code-vulnerability`
- **Mode**: `vf.ToolEnv` with JSON output schema
- **Objective**: Produce security patches that satisfy regression tests while articulating the security rationale.

## Dataset Construction

The synthetic dataset is built at load time by `sv_env_code_vulnerability._build_dataset` and currently contains two executable
tasks. Each entry stores:

- `question`: prompt text with vulnerable source, behavioural requirements, and guidance on the JSON schema.
- `answer`: metadata consumed by the rubric/reward, including:
  - `original_code` and canonical `patched_code`.
  - `expected_diff` computed via `difflib.unified_diff` for reproducible diffs.
  - `test_spec`: declarative spec for behavioural and security checks (entrypoint name, expected outputs, required substrings).
  - `explanation_keywords`: keywords required in the textual rationale.

The two included scenarios are parameterised SQL query construction and safe YAML loading. Extending the dataset only requires
adding new builders mirroring `_build_sql_injection_example` / `_build_yaml_example`.

## Tools

| Tool | Signature | Description |
| --- | --- | --- |
| `run_python_static_scan` | `(code: str) -> dict` | Flags common Python anti-patterns (AST-backed SQL concatenation detection, unsafe YAML loader, insecure randomness). |
| `run_patch_and_tests` | `(original_code: str, diff?: str, patched_code?: str, test_spec?: str) -> PatchTestResult` | Applies the provided diff/patched code, validates it against sandbox rules, and executes the declarative `test_spec`. Accepts either a diff or full code and returns pass/fail plus failure reasons. |

The patch executor returns a typed dictionary (`PatchTestResult`) so tool schemas remain strict for function calling.

## Reward

`reward_patch_and_test` combines multiple signals:

1. **Test execution (60%)** – delegates to `run_patch_and_tests` and scores 1.0 when regression tests pass.
2. **Diff similarity (20%)** – `difflib.SequenceMatcher` between submitted diff and canonical diff.
3. **Consistency (10%)** – compares claimed `tests_passed` to executor outcome.
4. **Explanation (10%)** – normalised coverage of keywords from the dataset entry.

If the executor fails and reports reasons, a small penalty (-0.1) is applied to guard against overly optimistic answers.

## Parser & Format Reward

`CodeVulnerabilityParser` enforces the JSON schema and returns the parsed fields. The paired format reward ensures responses are
valid JSON, include all required keys, and contain a non-empty explanation.

## Sandbox & Patch Application

- `apply_unified_diff` relies on `unidiff.PatchSet` to parse patches, rejecting malformed or multi-file diffs before any mutation happens.
- Patched code is validated via AST inspection (import allowlist + disallowed call detection) prior to compilation.
- Execution uses a read-only builtins mapping with a restricted `__import__`, preventing operations such as `eval`, `open`, or importing arbitrary modules.

## System Prompt

```
You are a secure code maintainer. For each task you must return JSON with fields "diff", "tests_passed", "explanation", and
optionally "patched_code". Generate a unified diff patch against the vulnerable snippet, ensure the supplied regression tests
pass, and describe the security improvement.
```

This prompt is surfaced automatically via `load_environment`.

## Testing

The new unit tests (`sv_env_code_vulnerability_test.py`) exercise:

- Parser parsing and format reward.
- Static scan heuristics.
- Unified diff application.
- Patch execution success/failure.
- Reward shaping for correct, incorrect, and regressive patches.
- Environment loader wiring (dataset length, tool schemas, rubric).

Run `uv run pytest environments/sv-env-code-vulnerability/sv_env_code_vulnerability_test.py` to validate locally.
